---
title: "Random Forest: Variable Importance"
author: "Peter Freeman (2019 SLSW)"
date: "8 July 2019"
output: 
  slidy_presentation:
    font_adjustment: -1
---

Explanation
===

This is an extra set of notes (meaning, it was not presented in lecture) that contains additional information about what the variable importance metrics of Random Forest mean. I also throw in some code at the very end that allows one to construct a `ggplot` version of a variable importance plot. 

These notes were not developed for the workshop and may or may not be intelligible! Contact me if you'd like further information.

Table
===

| | Regression | Classification |
| --- | --- | ---|
| %IncMSE | YES (but only if importance = TRUE) | NO |
| IncNodePurity | YES | NO  |
| MeanDecreaseGini | NO | YES |
| MeanDecreaseAccuracy | NO | YES |


If we ignore the `type` argument of the `importance()` function:

- Regression: if you do not specify `importance=TRUE`, only `IncNodePurity` is output. Otherwise `%IncMSE` is output in column 1, and `IncNodePurity` is output in column 2.

- Classification: if you do not specify `importance=TRUE`, only `MeanDecreaseGini` is output. Otherwise $p+2$ columns are output; `MeanDecreaseAccuracy` is output in column $p+1$ and `MeanDecreaseGini` is output in column $p+2$.

Considering the `type` argument just complicates things. We won't cover it here.

%IncMSE: Percentage Increase in MSE (Regression)
===

Algorithm:

1. Grow forest. Using OOB data, compute the MSE. Call this MSE.min.
2. For each predictor variable in turn, randomly permute the data values, then repeat Step 1. Call this MSE.ii.
3. %IncMSE for the ii<sup>th</sup> variable is 100*(MSE.ii-MSE.min)/(MSE.min).
4. Larger values are associated with more important predictor variables.

- Magnitude does not depend on sample size.

- This is analogous to `MeanDecreaseAccuracy`.

IncNodePurity: Increase in Node Purity
===

- How much does a split reduce the RSS? The output value represents the sum over all splits for that variable, averaged over all trees. That value will be larger or smaller depending on whether the dataset has a larger or smaller sample size.

- This is analogous to `MeanDecreaseGini`.

MeanDecreaseGini
===

- How much does a split reduce the Gini coefficient? The output value represents the (weighted?) sum over all splits for that variable, averaged over all trees. That value will be larger or smaller depending on whether the dataset has a larger or smaller sample size.

- This is analogous to `IncNodePurity`.

MeanDecreaseAccuracy
===

- How many more OOB observations are misclassified if we randomly permute the data in the named data frame column, as opposed to not permuting the data? (This is analogous to `%IncMSE`.)

- The magnitude will depend on sample size. Larger values are associated with more important predictor variables.

Variable Importance Plot: Example
===

Here we load the redshift data that we looked at in the Random Forest notes:
```{r echo=FALSE}
df = read.csv("https://raw.githubusercontent.com/pefreeman/PSU_2019/master/PhotoZ.csv")
set.seed(808)
s = sample(nrow(df),0.7*nrow(df))
pred.train = df[s,1:6]
pred.test  = df[-s,1:6]
resp.train = df[s,7]
resp.test  = df[-s,7]
if ( require(randomForest) == FALSE ) {
  install.packages("randomForest",repos="https://cloud.r-project.org")
  library(randomForest)
}
out.rf = randomForest(resp.train~.,data=pred.train,importance=TRUE)
```

Variable Importance Plot: Example
===

Below we provide a custom plotting function for plotting variable importance using `ggplot2`. This is very much an undocumented work in progress.
```{r}
ggVarImpPlot = function(importance,type="MSE",shiftFactor=10) {
  if ( require(ggplot2) == FALSE ) { stop("The ggplot2 package is required to execute this function.")}
  if ( require(grid)    == FALSE ) { stop("The grid package is required to execute this function.")}
  
  w = grep(type,colnames(importance))
  if ( length(w) > 0 ) {
    if ( type == "MSE") xlabel = "MSE: Percentage Increase"
    if ( type == "Purity") xlabel = "Increase in Node Purity"
    if ( type == "Gini") xlabel = "Gini: Mean Decrease"
    if ( type == "Accuracy") xlabel = "Accuracy: Mean Decrease"
    o = order(importance[,w])
    x = importance[o,w]
    var = rownames(importance)[o]
  } else {
    xlabel = colnames(importance)[1]
    o = order(importance[,1])
    x = importance[o,1]
    var = rownames(importance)[o]
  }

  n = length(x)
  y = (1:n)/(n+1)
  df = data.frame(x,y)

  p = ggplot(data=df,mapping=aes(x=x,y=y)) + geom_point(size=2) + xlim(0,max(x)) + ylim(0,1) + xlab(xlabel) + 
    theme(axis.title.y=element_blank(),axis.text.y=element_blank(),axis.ticks.y=element_blank()) +
    theme(plot.margin=unit(c(1,1,1,2),"cm"))
  for ( ii in 1:n ) {
    p = p + annotation_custom(grob = textGrob(label=var[ii]),ymin=y[ii],ymax=y[ii],xmin=-max(x)/shiftFactor,xmax=-max(x)/shiftFactor) +
      geom_hline(yintercept=y[ii],linetype="dashed",color="red",size=0.3)
  }
  gt <- ggplot_gtable(ggplot_build(p))
  gt$layout$clip[gt$layout$name == "panel"] <- "off"
  grid.draw(gt)
  invisible(list(p=p,gt=gt))
}

ggVarImpPlot(importance(out.rf))
```


